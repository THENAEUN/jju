# -*- coding: utf-8 -*-
"""07_02_TOKENTEXTSPLITTRT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/163AEZyfRggJOBeKfaX0PeUo30few0lQ6
"""

# 파일 객체 생성 및 내용을 읽어서 변수에 저장
with open('/content/appendix-keywords.txt') as f:
  file = f.read()

print(file[:600])

pip install langchain tiktoken

from langchain.text_splitter import CharacterTextSplitter

# 파일 읽기
input_file = 'appendix-keywords.txt'
output_file = '07_02_RESULT_TOKENEXTSPLITTER.TXT'

# 텍스트 읽기
with open(input_file, 'r', encoding='utf-8') as f:
    file_content = f.read()

text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    chunk_size = 400,
    chunk_overlap = 50,
)

# 텍스트를 나누기
texts = text_splitter.split_text(file_content)

# 나뉜 텍스트 출력
print(f"분할된 텍스트 조각 개수: {len(texts)}")
for i, text in enumerate(texts):  # 모든 텍스트 출력
    print(text.strip())  # "조각"을 없애고 텍스트만 출력
    print('=' * 80)  # 구분선 출력

# 결과를 파일에 저장
with open(output_file, 'w', encoding='utf-8') as f:
    for text in texts:
        f.write(text.strip() + '\n\n')

print(f"결과가 '{output_file}' 파일에 저장되었습니다.")

